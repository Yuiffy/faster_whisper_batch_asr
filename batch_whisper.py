import sys
import os
import time
import shutil
import traceback
import gc
from faster_whisper import WhisperModel, BatchedInferencePipeline

# ================= â„ï¸ RTX 5080 ç»ˆææ™ºèƒ½é™çº§ç‰ˆ â„ï¸ =================
# æ¨¡å‹è·¯å¾„
MODEL_SIZE = "deepdml/faster-whisper-large-v3-turbo-ct2"

# åŸºç¡€å¹¶å‘æ•° (Batchæ¨¡å¼ç”¨)
BATCH_SIZE = 12

# ã€åŠŸèƒ½å¼€å…³ã€‘æ˜¯å¦å¼€å¯é•¿å¥æ™ºèƒ½åˆ‡åˆ†
ENABLE_SMART_SPLIT = False
MAX_CHARS_PER_LINE = 18

# å®¹é”™é˜ˆå€¼ï¼šå¦‚æœç”Ÿæˆçš„æ—¶é•¿æ¯”è§†é¢‘çŸ­äº†è¶…è¿‡ 60ç§’ï¼Œè§¦å‘é™çº§
TOLERANCE_SECONDS = 60
MAX_RETRIES = 3

VIDEO_EXTS = {'.mp4', '.flv', '.mkv', '.avi', '.mov', '.webm', '.ts', '.m4v', '.m4a'}


# ===========================================================

def is_video_file(filename):
    return os.path.splitext(filename)[1].lower() in VIDEO_EXTS


def format_timestamp(seconds):
    if seconds is None: return "00:00:00,000"
    ms = int((seconds % 1) * 1000)
    seconds = int(seconds)
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"


# --- âœ‚ï¸ æ™ºèƒ½åˆ‡åˆ†ç®—æ³• âœ‚ï¸ ---
def smart_split_segment(segment, max_chars=18):
    if len(segment.text) <= max_chars or not segment.words:
        yield {"start": segment.start, "end": segment.end, "text": segment.text.strip()}
        return

    current_words = []
    current_len = 0
    segment_start = segment.words[0].start

    for word in segment.words:
        word_text = word.word
        word_len = len(word_text)
        if current_len + word_len > max_chars and current_words:
            yield {"start": segment_start, "end": current_words[-1].end,
                   "text": "".join([w.word for w in current_words]).strip()}
            current_words = []
            current_len = 0
            segment_start = word.start
        current_words.append(word)
        current_len += word_len

    if current_words:
        yield {"start": segment_start, "end": current_words[-1].end,
               "text": "".join([w.word for w in current_words]).strip()}


def transcribe_with_strategy(model, video_path, srt_path, total_duration):
    """
    ä¸‰çº§ç«ç®­ç­–ç•¥ï¼š
    1. Batchæ¨¡å¼: æé€Ÿï¼Œä½† ASMR å®¹æ˜“ä¸¢åŒ…
    2. Sequentialæ¨¡å¼: ç¨æ…¢ï¼Œä½†æåº¦ç¨³å®šï¼Œæ­»ç£•åˆ°åº•
    3. æ ¸å¼¹æ¨¡å¼: å…³é—­ VADï¼Œå¼ºè¡Œè½¬å†™æ¯ä¸€ç§’
    """
    prompt = "é¥¼å¹²å²ä»¬å¥½ï¼Œæˆ‘æ˜¯å²å·±ã€‚ä»Šå¤©ç›´æ’­ç©æ¸¸æˆï¼Œæ‚è°ˆå”±æ­Œã€‚å“å‘€ï¼Œè¿™ä¸ªå¥½éš¾å•Šï¼Ÿæ²¡å…³ç³»ï¼Œæˆ‘ä»¬å¯ä»¥çš„ã€‚è¯·å¤šå…³ç…§ã€‚"

    # ä¸´æ—¶æ–‡ä»¶ï¼Œé˜²æ­¢å†™åæ­£å¼æ–‡ä»¶
    temp_srt = srt_path + ".tmp"

    for attempt in range(1, MAX_RETRIES + 1):
        # --- ç­–ç•¥é€‰æ‹© ---
        use_batch = True
        use_vad = True
        strategy_name = "ğŸš€ [ç­–ç•¥1] æé€Ÿ Batch æ¨¡å¼"

        if attempt == 2:
            use_batch = False
            strategy_name = "ğŸ¢ [ç­–ç•¥2] ç¨³å¥ Sequential æ¨¡å¼ (ASMRä¸“ç”¨)"
        elif attempt == 3:
            use_batch = False
            use_vad = False
            strategy_name = "â˜¢ï¸ [ç­–ç•¥3] æ ¸å¼¹æ¨¡å¼ (å…³é—­VADï¼Œå¼ºåˆ¶å…¨å†™)"

        print(f"\nğŸ‘‰ ç¬¬ {attempt} æ¬¡å°è¯•: å¯ç”¨ {strategy_name}...")

        # ASMR ä¸“ç”¨å®½æ¾å‚æ•°
        vad_params = {
            "min_silence_duration_ms": 3000,
            "speech_pad_ms": 2000,
            "threshold": 0.3
        }

        start_time = time.time()
        last_segment_end = 0
        line_count = 0

        try:
            segments = None
            batched_model = None

            if use_batch:
                # ç­–ç•¥1ï¼šBatch Pipeline
                batched_model = BatchedInferencePipeline(model=model)
                segments, _ = batched_model.transcribe(
                    video_path,
                    batch_size=BATCH_SIZE,
                    language="zh",
                    initial_prompt=prompt,
                    vad_filter=True,
                    vad_parameters=vad_params,
                    word_timestamps=True
                )
            else:
                # ç­–ç•¥2 & 3ï¼šåŸç”Ÿä¸²è¡Œæ¨¡å¼ (ä¸ç»è¿‡ Pipeline)
                segments, _ = model.transcribe(
                    video_path,
                    beam_size=5,
                    language="zh",
                    initial_prompt=prompt,
                    vad_filter=use_vad,
                    vad_parameters=vad_params if use_vad else None,
                    word_timestamps=True,
                    condition_on_previous_text=False
                )

            # è¿›åº¦æ¡
            term_width = shutil.get_terminal_size().columns
            bar_width = max(20, term_width - 65)

            with open(temp_srt, "w", encoding="utf-8") as f:
                for raw_segment in segments:
                    last_segment_end = raw_segment.end

                    # åˆ‡åˆ†é€»è¾‘
                    if ENABLE_SMART_SPLIT:
                        sub_segments = smart_split_segment(raw_segment, MAX_CHARS_PER_LINE)
                    else:
                        sub_segments = [{
                            "start": raw_segment.start, "end": raw_segment.end, "text": raw_segment.text.strip()
                        }]

                    for split_seg in sub_segments:
                        line_count += 1

                        percent = (last_segment_end / total_duration) * 100
                        if percent > 100: percent = 100
                        elapsed = time.time() - start_time
                        speed = last_segment_end / elapsed if elapsed > 0 else 0
                        eta = (total_duration - last_segment_end) / speed if speed > 0 else 0

                        filled = int(bar_width * percent / 100)
                        bar = 'â–ˆ' * filled + '-' * (bar_width - filled)

                        icon = "âš¡" if use_batch else "ğŸ¢"
                        sys.stdout.write(f"\r   {icon} {percent:5.1f}% [{bar}] ETA:{int(eta)}s | {speed:.1f}x")
                        sys.stdout.flush()

                        start_s = format_timestamp(split_seg['start'])
                        end_s = format_timestamp(split_seg['end'])
                        text = split_seg['text']
                        f.write(f"{line_count}\n{start_s} --> {end_s}\n{text}\n\n")

                    f.flush()

            print()

            # === ğŸ›¡ï¸ å®Œæ•´æ€§æ£€æŸ¥ ===
            missing = total_duration - last_segment_end

            # åªæœ‰å½“ç¼ºå¤±ä¸¥é‡ï¼Œä¸”è§†é¢‘æœ¬èº«ä¸æ˜¯ç‰¹åˆ«çŸ­
            if missing > TOLERANCE_SECONDS and total_duration > 120:
                print(f"   âš ï¸  è­¦å‘Š: ç¼ºå¤± {missing:.1f} ç§’ (æ€»é•¿ {format_timestamp(total_duration)})")

                if attempt < MAX_RETRIES:
                    print(f"   ğŸš« å½“å‰ç­–ç•¥ä¸é€‚åˆæ­¤è§†é¢‘ (ASMRéŸ³é‡è¿‡ä½)ï¼Œå‡†å¤‡åˆ‡æ¢ç­–ç•¥é‡è¯•...")
                    time.sleep(2)
                    continue  # è§¦å‘ä¸‹ä¸€æ¬¡å¾ªç¯(æ¢ç­–ç•¥)
                else:
                    print(f"   ğŸ’€ æ‰€æœ‰ç­–ç•¥è€—å°½ï¼Œä¿ç•™ç°æœ‰ç»“æœã€‚")

            # æˆåŠŸï¼šç§»åŠ¨ä¸´æ—¶æ–‡ä»¶åˆ°ç›®æ ‡è·¯å¾„
            if os.path.exists(srt_path): os.remove(srt_path)
            os.rename(temp_srt, srt_path)
            print(f"   âœ… æˆåŠŸç”Ÿæˆï¼è€—æ—¶: {time.time() - start_time:.1f}s")

            # æ¸…ç†å†…å­˜
            if batched_model: del batched_model
            gc.collect()
            return

        except Exception as e:
            print(f"\n   âŒ å‡ºé”™: {e}")
            traceback.print_exc()
            time.sleep(2)


def process_one_video(model, video_path, file_idx, total_files):
    filename = os.path.basename(video_path)
    output_dir = os.path.dirname(video_path)
    filename_no_ext = os.path.splitext(filename)[0]
    srt_path = os.path.join(output_dir, filename_no_ext + ".srt")

    # --- æ™ºèƒ½é˜²è¦†ç›–é€»è¾‘ (ä½ è¦æ±‚çš„) ---
    counter = 1
    original_srt_path = srt_path
    while os.path.exists(srt_path):
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ä½†å¾ˆå°(å¯èƒ½æ˜¯å¤±è´¥çš„äº§ç‰©)ï¼Œç›´æ¥è¦†ç›–ï¼›å¦åˆ™é‡å‘½å
        if os.path.getsize(srt_path) < 100:
            break
        new_filename = f"{filename_no_ext}_{counter}.srt"
        srt_path = os.path.join(output_dir, new_filename)
        counter += 1

    if counter > 1:
        print(f"âœ¨ è‡ªåŠ¨é‡å‘½åä¸º: {os.path.basename(srt_path)}")
    # ------------------

    print(f"\nğŸ¬ [{file_idx}/{total_files}] æ­£åœ¨å¤„ç†: {filename}")

    try:
        # è·å–æ—¶é•¿ (ä¸ä½¿ç”¨ pipelineï¼Œä½¿ç”¨åŸç”Ÿ model å¿«é€Ÿæ¢æµ‹)
        print("   ğŸ” åˆ†æè§†é¢‘æ—¶é•¿...", end="", flush=True)
        _, info = model.transcribe(video_path, beam_size=1, temperature=0, no_speech_threshold=1.0,
                                   condition_on_previous_text=False)
        total_duration = info.duration
        print(f" -> {format_timestamp(total_duration)}")

        # æ ¸å¿ƒé€»è¾‘
        transcribe_with_strategy(model, video_path, srt_path, total_duration)

    except Exception as e:
        print(f"\n   âŒ é¢„å¤„ç†å¤±è´¥: {e}")


def main():
    os.system('cls' if os.name == 'nt' else 'clear')
    if len(sys.argv) < 2:
        print("âŒ è¯·æ‹–æ‹½æ–‡ä»¶ï¼")
        return

    input_path = sys.argv[1]
    todo_list = []
    if os.path.isfile(input_path):
        if is_video_file(input_path): todo_list.append(input_path)
    else:
        for root, dirs, files in os.walk(input_path):
            for file in files:
                if is_video_file(file): todo_list.append(os.path.join(root, file))

    print(f"ğŸ”¥ æ­£åœ¨åŠ è½½ RTX 5080 å¼•æ“ (ASMR æ™ºèƒ½ç‰ˆ)...")
    try:
        # è¿™é‡ŒåªåŠ è½½åŸºç¡€æ¨¡å‹ï¼ŒBatchPipeline åœ¨ç­–ç•¥1é‡ŒåŠ¨æ€åˆ›å»º
        model = WhisperModel(MODEL_SIZE, device="cuda", compute_type="float16")
    except Exception as e:
        print(f"âŒ æ˜¾å¡æŠ¥é”™: {e}")
        return

    for idx, video_path in enumerate(todo_list, start=1):
        process_one_video(model, video_path, idx, len(todo_list))
        gc.collect()

    print(f"\nğŸ† å…¨éƒ¨å®Œæˆï¼")


if __name__ == "__main__":
    main()